{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import load_tools\n",
    "from langchain.tools import AIPluginTool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshua\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\custom-openai-api-endpoint-w1RmsYNt-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 10843.60it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of documents :3\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://docs.kamino.finance/\",\n",
    "    \"https://docs.kamino.finance/kamino-lend-litepaper\",\n",
    "    \"https://docs.kamino.finance/products/overview\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "print(f\"len of documents :{len(docs_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of document chunks generated :8\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "print(f\"length of document chunks generated :{len(doc_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Kamino Portal | Hub | Kamino DocsKamino DocsHubHubRiskAutomated LiquiditySearchCtrl\\u2006+\\u2006KKamino PortalKamino Lend LitepaperProductsOverviewMultiplyHow ToOpen a PositionManage a PositionManage RiskHow It WorksRisksBorrow/LendSupplying AssetskToken CollateralBorrowing AssetsPosition Risk & LiquidationsPosition RiskBorrow FactorsFeesLong/ShortLiquidityKamino PointsOverviewRates & BoostsSeasonsSeason 1Season 2PageReferralsAutomated LiquidityLiquidity VaultskTokensLiquidity AnalyticsLiquidity Vault RisksSecurity & RiskRisk FrameworkOracle SecurityLive Risk DashboardAuto-deleverageInterest Rate ModelAsset RiskAuditsBuild on KaminoSDK & Smart ContractsDeveloper DocumentationBug BountyBrand AssetsKMNOToken InfoStakingPowered by GitBookKamino PortalAutomated products powered by secure DeFi primitivesWhat is Kamino Finance?Kamino Finance was originally created to offer users the easiest possible way of providing liquidity and earning yield on-chain.The protocol's one-click, auto-compounding concentrated liquidity strategies quickly became the most popular LP products on Solana, and laid the foundation for what Kamino is now.Today, Kamino is a first-of-its-kind DeFi protocol that unifies Lending, Liquidity, and Leverage into a single, secure DeFi product suite. On Kamino, users can:Borrow and lend their assetsProvide leveraged liquidity to concentrated liquidity DEXsBuild their own automated liquidity strategiesUse concentrated liquidity positions as collateralKamino's product suite is packaged into an industry-leading UX that offers transparent analytics, detailed performance data, and extensive position info.Our ProductsDive inThis portal consists of the Kamino Lend Litepaper, extensive technical documentation, how-to protocol guides, and live risk and analytics dashboards.Join Kamino's Community Discord if you need any help building on Kamino, or using the protocol.NextKamino Lend LitepaperLast updated 1 month agoOn this pageWhat is Kamino Finance?Our ProductsDive inEarn Interest and BorrowBoosted SOL YieldsIncrease Your ExposureAutomated LP StrategiesCustom LP Strategies\", metadata={'source': 'https://docs.kamino.finance/', 'title': 'Kamino Portal | Hub | Kamino Docs', 'description': 'Automated products powered by secure DeFi primitives', 'language': 'en'}),\n",
       " Document(page_content='Kamino Lend Litepaper | Hub | Kamino DocsKamino DocsHubHubRiskAutomated LiquiditySearchCtrl\\u2006+\\u2006KKamino PortalKamino Lend LitepaperProductsOverviewMultiplyHow ToOpen a PositionManage a PositionManage RiskHow It WorksRisksBorrow/LendSupplying AssetskToken CollateralBorrowing AssetsPosition Risk & LiquidationsPosition RiskBorrow FactorsFeesLong/ShortLiquidityKamino PointsOverviewRates & BoostsSeasonsSeason 1Season 2PageReferralsAutomated LiquidityLiquidity VaultskTokensLiquidity AnalyticsLiquidity Vault RisksSecurity & RiskRisk FrameworkOracle SecurityLive Risk DashboardAuto-deleverageInterest Rate ModelAsset RiskAuditsBuild on KaminoSDK & Smart ContractsDeveloper DocumentationBug BountyBrand AssetsKMNOToken InfoStakingPowered by GitBookKamino Lend LitepaperAs published in October 2023This litepaper introduces Kamino Lend (K-Lend), a novel peer-to-pool borrowing primitive designed as foundational infrastructure to power complex financial products with leverage and automation, and as a decentralized matchmaker between borrowers and lenders.K-Lend underpins Kamino 2.0, which is a fully integrated dApp unifying borrowers, lenders, and liquidity providers - allowing users to express more market views than ever before, and enabling them to participate throughout all phases of the market cycle.K-Lend features:Unified Liquidity MarketElevation Mode (eMode)CLMM LP Tokens as CollateralPoly-linear Interest CurveProtected CollateralAuto-deleverageAsset TiersReal-time Risk SimulatorAdvanced Oracle Risk EngineSoft LiquidationsDynamic LiquidationsUnified Liquidity MarketK-Lend features a single liquidity market, rather than a multi-pool design. Within this market, K-Lend introduces an ‘eMode’ mechanism that enables higher leverage when lending/borrowing solely within a certain asset grouping.Multi-pool designs have shown to be inefficient in lending protocols, fragmenting liquidity and ultimately leading to lower utilizations and lower yields for lenders. In practice, the primary benefit of a multi-pool design is that each isolated pool (i.e. different asset combinations) can have custom parameters, while separating risk from the main liquidity market.However, K-Lend’s risk engine allows for risk isolation even within a unified liquidity market, while', metadata={'source': 'https://docs.kamino.finance/kamino-lend-litepaper', 'title': 'Kamino Lend Litepaper | Hub | Kamino Docs', 'description': 'As published in October 2023', 'language': 'en'}),\n",
       " Document(page_content='the protocol’s eMode infrastructure enables customized asset parameters within a single market.Elevation ModeElevation Mode (first introduced in Aave V3 as Efficiency Mode) allows users to borrow highly correlated or soft-pegged assets at a more capital-efficient LTV ratio. Within K-Lend’s unified liquidity market, assets can be grouped into “elevation groups (eGroups)”. Each eGroup can have customized LTV parameters and liquidation thresholds assigned to it, ultimately unlocking higher leverage possibilities, as well as tailored liquidation parameters.Crucially, elevation groups are built into the main liquidity market. All K-Lend users can thus access the unified liquidity market, while eMode empowers them to attain greater capital efficiency and higher leverage via customized asset parameters.For instance, if all SOL and SOL LST tokens are grouped into an eGroup with a 95% max LTV, all the tokens will adopt 95% as their new max LTV. Any supply/borrowing within this asset grouping can then be done at this LTV, allowing for increased capital efficiency and leverage between these assets.Combined with Kamino’s automation infrastructure, eMode also enables the platform to offer more powerful looping products than exist anywhere on Solana.CLMM LP Tokens as Collateral (kTokens)The growth of Uni V3 and concentrated liquidity as DeFi’s primary liquidity model has virtually stopped leveraged LPing in its tracks. This is because LP positions from CLMMs are non-fungible, and cannot easily be used as collateral nor levered up.Poly-linear Interest Rate CurveInterest rate (IR) curves dictate supply and borrow rates based on an asset’s utilization rate. Interest rates are intended to keep markets at an equilibrium, while ensuring lenders are able to access their liquidity should they wish to withdraw capital. A multi-point IR curve reduces shocks to the system by more gradually increasing or decreasing rates when necessary.With theoretically up to 11 points on its IR curve, K-Lend provides a major improvement over traditional 3-point curves in other lending markets. This is beneficial to borrowers who are subject to more gradual rate increases before repaying their debt.Protected CollateralOn K-Lend, users can opt to keep their collateral assets from being borrowed by other users, thus protecting their assets from any borrower default risks.Such assets, referred to as “Protected Collateral”, can still be used', metadata={'source': 'https://docs.kamino.finance/kamino-lend-litepaper', 'title': 'Kamino Lend Litepaper | Hub | Kamino Docs', 'description': 'As published in October 2023', 'language': 'en'}),\n",
       " Document(page_content='as collateral for borrowing by the depositor, but they do not earn interest on these assets. Protected collateral can be withdrawn at any time.Risk ManagementDeposit CapsEach asset on Kamino Lend is subject to a deposit cap, ensuring that the system contains a safe amount of any asset at any given time based on the asset risk score, which takes into account various risk metrics, such as the available market liquidity, the volatility of the asset, the security risk of the asset etc. These caps are continuously monitored and are subject to readjustments if deemed necessary.Borrow CapsSimilarly, borrow caps limit the borrowing of each asset to a certain amount, based on the asset risk score. This is continuously assessed and subject to change if deemed necessary.Auto-DeleveragingKamino’s auto-deleverage mechanism lowers the deposit and/or borrow caps of a certain asset to an amount that is deemed safe considering current market conditions. Lowering the caps thus triggers an automated unwinding event.If an auto-deleverage event is triggered on USDH deposits for example, users are notified via Kamino’s communication channels, and given a specified period to adjust any positions using USDH as collateral. Once this period elapses, the system begins partial deleveraging of loans backed by USDH, starting with loans closest to liquidation.Deleveraged loans incur a minor liquidation penalty which escalates continuously up to a maximum, until the target collateral/borrowing amount is achieved. Users subject to deleveraging will see a proportional reduction in the target asset, along with the corresponding tokens in the position, generally resulting in a more healthy Loan-to-Value (LTV) ratio.Asset TiersA unified liquidity market offers considerable benefits to borrowers and lenders, but it also presents new challenges to risk management. Risk can easily spill over from one asset to another, ultimately increasing the risk of bad debt on the protocol. K-Lend will introduce Asset Tiers to ensure that users can borrow and lend a wide range of tokens safely, without fracturing liquidity between isolated pools.A tier-based system allows the protocol to offer permissionless borrowing and lending for any token on Solana, with Kamino’s Risk Council determining the ways an asset can be used on the protocol, grading each asset into one of three categories: Isolated Debt, Isolated Collateral, and General. Isolated DebtCan be borrowed, but only in isolation from other assets. These assets cannot be', metadata={'source': 'https://docs.kamino.finance/kamino-lend-litepaper', 'title': 'Kamino Lend Litepaper | Hub | Kamino Docs', 'description': 'As published in October 2023', 'language': 'en'}),\n",
       " Document(page_content='used as collateral, but can be supplied for lending yield.Isolated CollateralCan only be used as collateral, and only in isolation from other assets. Isolated Debt assets cannot be borrowed against Isolated Collateral.GeneralCan be used as collateral to borrow other assets, and can be borrowed alongside other general assets. This will typically represent the most liquid assets on the network.Borrow FactorsBorrow factors (BFs) are risk-adjusted borrow values assigned to each asset on K-Lend. This determines the borrowing capacity of a debt asset within a loan, based on its Asset Risk Score.This is parallel to loan-to-value ratios (LTVs), which indicate borrowing limits from the collateral asset perspective.K-Lend combines LTV and BF to express a weighted borrowing capacity based on the asset composition of a position. This allows the protocol much more flexibility in assessing the risk of each position on the platform.For example, let’s assume you want to supply $100 of SOL as collateral and borrow either USDC or BONK:SOL is a widely circulating collateral asset, and its maximum LTV ratio = 80% USDC is deemed a less risky asset than BONK.USDC Borrow Factor = 1BONK Borrow Factor = 2Borrow capacity is expressed as: (Collateral Amount * Collateral LTV) / Borrow FactorUSDC borrow capacity against SOL  = ($100 * 80%) / 1 = $80For BONK, due to a BF of 2, you can borrow up to $40.Similar to the above expression of risk-adjusted borrowing capacity, the liquidation point of any loan is also calculated as a weighted expression of LTV and borrow factor.Risk SimulatorIn contrast with TradFi standards, DeFi platforms often provide users with limited tooling to help them understand, model and simulate position risk. Kamino has built a Risk Simulator that allows K-Lend users to view their position risk and simulate market movements.The simulator shows the impact on portfolio value, LTV, liquidation delta, and more.OraclesOracles have historically been the most common attack vector for DeFi exploits. K-Lend’s oracle risk engine combines various risk practices such as heuristic and EWMA prices, while also maintaining its own oracles alongside those from other providers.TWAP and EWMA PricesSimilar to price bands, Time Weighted Average Prices (TWAP) and Exponentially Weighted Moving Average', metadata={'source': 'https://docs.kamino.finance/kamino-lend-litepaper', 'title': 'Kamino Lend Litepaper | Hub | Kamino Docs', 'description': 'As published in October 2023', 'language': 'en'}),\n",
       " Document(page_content='(EWMA) prices are resistant to price manipulations because they identify the average price of an asset over time.Since K-Lend uses TWAPs and EWMAs, the protocol is protected from flash loans/flash crashes, as dramatic short term price changes are rejected. Exploiting the protocol via price manipulation is thus expensive, as it requires the exploiter not only to manipulate a price, but to sustain it for some period of time relative to the existing TWAP/EWMA intervals.Price BandsEach stable or soft-pegged asset in K-Lend has a price range within which the smart contract expects the price to fall within. This is referred to as the price-band, and alongside TWAP/EWMA, also protects the protocol from flash crashes and flash-loan exploits.For example, USD-pegged stables like USDC and USDH could have a 1% upper or lower band from $1. In this case, if the price is above $1.01, the price would be rejected. For SOL-pegged assets, price bands would be expressed relative to the SOL price.Multiple ProvidersK-Lend cross-references oracles from both Pyth and Switchboard, as well as its own Switchboard oracles that ingest feeds from various on-chain and off-chain sources.For kTokens, Kamino computes prices directly on-chain. Each kToken price is calculated atomically, based on various price sources and the current state of the strategy.LiquidationsK-Lend introduces a range of improvements to the liquidation process; from encouraging greater liquidator participation, to softening the burden on borrowers.Partial LiquidationsInstead of liquidations closing a borrower’s position in its entirety, K-Lend enables soft liquidations that settle, for example, 20% of a user’s debt. In this scenario, users who are only slightly over the liquidation LTV are not severely punished - whereas users who far exceed the liquidation LTV can be liquidated to a greater degree.Dynamic Liquidation PenaltiesLiquidation penalties have been traditionally high in DeFi to make up for low speeds, high gas fees, and network/market volatility. If a liquidator catches a falling knife and cannot liquidate those assets quickly, then they lose money. As a result, liquidation penalties have typically been 5-10% or more.On K-Lend, liquidation penalties start at 2% and are capped at', metadata={'source': 'https://docs.kamino.finance/kamino-lend-litepaper', 'title': 'Kamino Lend Litepaper | Hub | Kamino Docs', 'description': 'As published in October 2023', 'language': 'en'}),\n",
       " Document(page_content=\"10%. If the most efficient liquidators execute liquidations as soon as possible, borrowers are subject only to a 2% penalty. The liquidation penalty increases as the loan LTV increases, until the loan is liquidated. This system is designed to reward the most efficient liquidators, while simultaneously softening the blow to borrowers.Example: Instant LiquidationUser A’s loan reaches the liquidation LTV of 80%. The liquidator triggers the liquidation shortly after the loan is eligible. The liquidator repays 20% of the debt and receives 20.4% (0.2 * 0.02) of User A’s collateral. User A now has less collateral, less debt, and a lower LTV, and their loan position remains active.Example: Eventual LiquidationUser B’s loan reaches the liquidation threshold of 80% LTV. The liquidator doesn't act instantly and the liquidation penalty rises to 10% as the loan reaches a 90% LTV. At that point the liquidator steps in and liquidates the position. He repays 20% of the debt and receives 22% (0.2 * 0.1) of User B’s collateral.PreviousKamino PortalNextOverviewLast updated 7 months agoOn this pageUnified Liquidity MarketElevation ModeCLMM LP Tokens as Collateral (kTokens)Poly-linear Interest Rate CurveProtected CollateralRisk ManagementDeposit CapsBorrow CapsAuto-DeleveragingAsset TiersBorrow FactorsRisk SimulatorOraclesTWAP and EWMA PricesPrice BandsMultiple ProvidersLiquidationsPartial LiquidationsDynamic Liquidation PenaltiesKamino’s  already tokenizes CLMM LP positions. These positions, called kTokens, are fungible, easily liquidatable SPL tokens. K-Lend supports these kTokens as collateral, allowing users to use leverage by borrowing against / looping their LP positions.Elevation Mode IllustrationPoly-linear Interest Rate Curve IllustrationAuto-deleverage IllustrationAsset Tier Illustrationautomated liquidity infrastructure\", metadata={'source': 'https://docs.kamino.finance/kamino-lend-litepaper', 'title': 'Kamino Lend Litepaper | Hub | Kamino Docs', 'description': 'As published in October 2023', 'language': 'en'}),\n",
       " Document(page_content='Overview | Hub | Kamino DocsKamino DocsHubHubRiskAutomated LiquiditySearchCtrl\\u2006+\\u2006KKamino PortalKamino Lend LitepaperProductsOverviewMultiplyHow ToOpen a PositionManage a PositionManage RiskHow It WorksRisksBorrow/LendSupplying AssetskToken CollateralBorrowing AssetsPosition Risk & LiquidationsPosition RiskBorrow FactorsFeesLong/ShortLiquidityKamino PointsOverviewRates & BoostsSeasonsSeason 1Season 2PageReferralsAutomated LiquidityLiquidity VaultskTokensLiquidity AnalyticsLiquidity Vault RisksSecurity & RiskRisk FrameworkOracle SecurityLive Risk DashboardAuto-deleverageInterest Rate ModelAsset RiskAuditsBuild on KaminoSDK & Smart ContractsDeveloper DocumentationBug BountyBrand AssetsKMNOToken InfoStakingPowered by GitBookOverviewKamino offers a suite of products that combine a variety of DeFi primitives to power sophisticated strategies - each wrapped into an accessible, user-centric interface.Kamino has built two core primitives:Automated Liquidity VaultsKamino LendThese primitives combine to power these one-click products:Multiply VaultsLong/Short VaultsPreviousKamino Lend LitepaperNextMultiplyLast updated 2 months agoOn this page', metadata={'source': 'https://docs.kamino.finance/products/overview', 'title': 'Overview | Hub | Kamino Docs', 'language': 'en'})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=doc_splits,\n",
    "                                    embedding=embed_model,\n",
    "                                    collection_name=\"local-rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'web_search'}\n",
      "The time required to generate response by Router Chain in seconds:1.1396307945251465\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on Kamino Portal, \n",
    "    Kamino Lend Litepaper, and Kamino Overview. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "#\n",
    "question = \"llm agent memory\"\n",
    "print(question_router.invoke({\"question\": question}))\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by Router Chain in seconds:{end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "start = time.time()\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n",
      "The time required to generate response by the retrieval grader in seconds:0.8524599075317383\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "start = time.time()\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"kamino\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the retrieval grader in seconds:{end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the generation chain in seconds:0.9329128265380859\n",
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "start = time.time()\n",
    "generation = []\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader_response = hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the generation chain in seconds:{end - start}\")\n",
    "print(hallucination_grader_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the answer grader in seconds:0.8401024341583252\n",
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader_response = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the answer grader in seconds:{end - start}\")\n",
    "print(answer_grader_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment variables\n",
    "URL = \"https://blockchatstatic.blob.core.windows.net/api-configuration\"\n",
    "\n",
    "tools = load_tools([\"requests_post\"], allow_dangerous_tools=True)\n",
    "\n",
    "# AIPluginTool only fetches and returns the openapi.yaml linked to in /.well-known/ai-plugin.json\n",
    "# This may need some more work to avoid blowing up LLM context window\n",
    "solana_search_tool = AIPluginTool.from_plugin_url(URL + \"/.well-known/ai-plugin.json\")\n",
    "tools += [solana_search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "tools += [web_search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {query}\n",
    "Thought:{agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup an agent to answer the question without further human feedback\n",
    "agent = create_react_agent(\n",
    "    llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question : str\n",
    "    generation : str\n",
    "    web_search : str\n",
    "    documents : List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "#\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "#\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "#\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = agent_executor.invoke({\"query\": question})\n",
    "    web_results = docs[\"output\"]\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})  \n",
    "    print(source)\n",
    "    print(source['datasource'])\n",
    "    if source['datasource'] == 'web_search':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source['datasource'] == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generatae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "What is prompt engineering?\n",
      "{'datasource': 'web_search'}\n",
      "web_search\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use tavily_search_results_json to search for information on prompt engineering.\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"prompt engineering\"\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'https://www.coursera.org/articles/what-is-prompt-engineering', 'content': 'Examples of prompt engineering\\nHere are a few examples of prompt engineering to give you a better understanding of what it is and how you might engineer a prompt with a text and image model.\\n Learners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals.\\n$1 unlocks unlimited opportunities\\nCoursera Footer\\nPopular AI Content\\nPopular Programs\\nPopular Skills\\nPopular Career Resources\\nCoursera\\nCommunity\\nMore You can do the same for text-to-image models like DALL-E.\\nWhy is it important in generative AI?\\nPrompt engineering is important for AI engineers to create better services, such as chatbots that handle customer service tasks or generate legal contracts. If you do need to include “tone” in your prompt, should you write “in a professional tone” or “in a formal tone”?\\n Whether you’re inputting prompts in ChatGPT to help you write your resume or using DALL-E to generate a photo for a presentation, anybody can be a prompt engineer.\\xa0'}, {'url': 'https://platform.openai.com/docs/guides/prompt-engineering/prompt-engineering', 'content': 'Learn how to get better results from large language models like GPT-4 by using clear instructions, reference text, subtasks, external tools, and more. See examples of prompt engineering tactics and strategies for various tasks and domains.'}, {'url': 'https://www.ibm.com/topics/prompt-engineering', 'content': 'It is also the purview of the prompt engineer to understand how to get the best results out of the variety of generative AI models on the market. Tech-led disruptions are accelerating, driven by generative AI\\nBook a live demo of IBM® watsonx.ai\\nGenerative AI models are built on transformer architectures, which enable them to grasp the intricacies of language and process vast amounts of data through neural networks. For example, researchers developed a new AI system that can translate language without being trained on a parallel text; engineers are embedding generative AI in games to engage human players in truly responsive storytelling and even to gain accurate new insights into the astronomical phenomena of black holes. Generative AI relies on the iterative refinement of different prompt engineering techniques to effectively learn from diverse input data and adapt to minimize biases, confusion and produce more accurate responses.\\n Prompt engineering helps generative AI models better comprehend and respond to a wide range of queries, from the simple to the highly technical.\\n'}, {'url': 'https://www.promptingguide.ai/introduction', 'content': 'Learn how to develop and optimize prompts for large language models (LLMs) for various applications and use cases. This guide covers the basics of prompting, prompt elements, general tips, examples and LLM settings.'}, {'url': 'https://developers.google.com/machine-learning/resources/prompt-eng', 'content': 'Role Prompting:\\nData Organization:\\nPrompting with examples (One-, few-, and multi-shot)\\nOne-shot prompting shows the model one clear, descriptive example of what\\nyou\\'d like it to imitate.\\n Few-shot sentiment classification:\\nWhen this prompt is run, the model\\'s response will be to classify \\'It doesn\\'t\\nwork\\' as positive or negative, as shown in the examples.\\n It works better than zero-shot for more complex tasks where pattern\\nreplication is wanted, or when you need the output to be structured in a\\nspecific way that is difficult to describe.\\n You can also phrase the\\ninstruction as a question, or give the model a \"role,\" as seen in the second\\nexample below.\\n Multi-shot emoji response predictor:\\nSame process here, but since the prompt is more complex, the model has been\\ngiven more examples to emulate.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mI have found information on prompt engineering from various sources.\n",
      "Action: No action needed\n",
      "Final Answer: Prompt engineering involves creating clear instructions, reference text, subtasks, and external tools to get better results from large language models like GPT-4. It is important for AI engineers to create better services, such as chatbots and legal contracts.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "('Prompt engineering involves creating clear instructions, reference text, '\n",
      " 'subtasks, and external tools to improve results from large language models '\n",
      " 'like GPT-4. It is essential for AI engineers to enhance services like '\n",
      " 'chatbots and legal contracts.')\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"What is prompt engineering?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "What is Kamino Finance?\n",
      "{'datasource': 'web_search'}\n",
      "web_search\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use tavily_search_results_json to search for information about Kamino Finance.\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Kamino Finance\"\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'https://web-kamino.finance/', 'content': 'Kamino Finance is a decentralized finance protocol that allows users to borrow, lend, and leverage their assets with competitive interest rates and flexible terms. Users can also boost their SOL yields, provide liquidity to DEXs, and access automated strategies and analytics with Kamino.'}, {'url': 'https://app.kamino.finance/', 'content': 'Kamino is a Solana DeFi protocol that unifies Lending, Liquidity, and Leverage into a single, secure DeFi product suite. You can use Kamino to borrow and lend crypto assets; leverage your SOL staking yield, provide leveraged liquidity to DEXs, and earn automated market making yields. Deploy any Solana assets for yield, including SOL, USDC, USDT ...'}, {'url': 'https://www.coingecko.com/en/coins/kamino', 'content': 'Kamino Finance is a DeFi platform that offers lending, liquidity, and leverage products on Solana. Learn about KMNO price, market cap, trading volume, all-time high and low, and how to buy KMNO tokens.'}, {'url': 'https://www.coingecko.com/learn/what-is-kamino-finance-kmno', 'content': \"Kamino Finance is a DeFi product suite that combines lending, liquidity, and leverage with concentrated liquidity management. Learn how to use Kamino's features like Borrow and Lend, Multiply Vaults, Long/Short Vaults, Liquidity Vaults, and DIY Vault Creator.\"}, {'url': 'https://v2.kamino.finance/', 'content': \"Kamino Finance is built on top of Solana's DEXs such as Orca DEX and Raydium Exchange, to offer automated yield vaults. Kamino offers vaults on Hubble Stablecoin (USDH), Lido Staked SOL (stSOL), SOL (Solana), Circle USDC, Tether USDT, Raydium Native Token (RAY), Bonk Inu Token (BONK), Degods Dust Protocol (DUST), Wrapped Ethereum Solana (Wormhole, wETH), UXD Protocol Stablecoin (UXD ...\"}]\u001b[0m\u001b[32;1m\u001b[1;3mKamino Finance is a decentralized finance protocol on Solana that offers borrowing, lending, leverage, and automated yield vaults. \n",
      "Final Answer: Kamino Finance is a DeFi platform on Solana that provides various financial services such as borrowing, lending, leverage, and automated yield vaults.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "('Kamino Finance is a DeFi platform on Solana that offers borrowing, lending, '\n",
      " 'leverage, and automated yield vaults.')\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"What is Kamino Finance?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "How many SOL does 8fbqVvpK3Dj7fdP2c8JJhtD7Zy3n9qtwAeGfbkgPu625 have?\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: grade_documents:'\n",
      "---WEB SEARCH---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Solana Labs API to get information about the SOL balance of a specific address.\n",
      "Action: solana\u001b[0mInvalid Format: Missing 'Action Input:' after 'Action:'\u001b[32;1m\u001b[1;3mI need to provide an action input after calling the solana tool.\n",
      "Action: solana\n",
      "Action Input: \u001b[0m\u001b[33;1m\u001b[1;3mUsage Guide: This extension is for exploring Solana blockchain data, such as inspecting what tokens a wallet has or explaining what happened in a transaction. Use it whenever a user asks something that might be related to their Solana account or transaction history.\n",
      "\n",
      "OpenAPI Spec: {'openapi': '3.0.2', 'info': {'title': 'Solana Labs API', 'description': 'An API for retrieving human-readable information about the Solana blockchain.', 'version': '1.0.0'}, 'servers': [{'url': 'https://chatgpt.solanalabs.com/'}], 'paths': {'/api/handlers/getAssetsByOwner': {'post': {'summary': 'getAssetsByOwner', 'description': 'Accepts Solana publicKey address. Returns Metaplex NFTs owned by the address', 'operationId': 'query_assets_by_owner', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getAccountInfoRequest'}}}, 'required': True}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getAccountInfo': {'post': {'summary': 'getAccountInfo', 'description': \"Returns information about the data stored by that account in a human-readable format. Human-readable formatting is only possible when the account's corresponding program owner has published an Anchor IDL on the Solana blockchain.\", 'operationId': 'query_account_info', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getAccountInfoRequest'}}}, 'required': True}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getTokenAccounts': {'post': {'summary': 'getTokenAccounts', 'description': 'Returns the fungible and non-fungible tokens and amounts owned by the address. May show tokens not listed in get_assets_by_owner.', 'operationId': 'query_token_accounts', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getBalanceRequest'}}}, 'required': True}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getBalance': {'post': {'summary': 'getBalance', 'description': 'Accepts Solana publicKey address. Returns the amount of lamports that the account has available.', 'operationId': 'query_balance', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getBalanceRequest'}}}, 'required': True}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getTransaction': {'post': {'summary': 'getTransaction', 'description': 'Accepts a transaction signature. Returns the publicly available transaction information and metadata. Only high level summaries based on instruction data should be provided to users unless otherwise specified. Logs, compute units, and fees are available in devMode.', 'operationId': 'query_transaction', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getTransactionRequest'}}}}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getSignaturesForAddress': {'post': {'summary': 'getSignaturesForAddress', 'description': 'Accepts Solana publicKey address. Returns the latest transaction signatures that involve that address.', 'operationId': 'query_signatures_for_address', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getSignaturesForAddressRequest'}}}, 'required': True}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getCollectionsByFloorPrice': {'post': {'summary': 'Search through Solana NFT collections by floor price', 'operationId': 'query_nft_collections_by_fp', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getCollectionsByFloorPriceRequest'}}}}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getListedCollectionNFTs': {'post': {'summary': 'Returns the listed NFTs in a collection available to purchase', 'operationId': 'query_listed_nfts_for_collection', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getListedCollectionNFTsRequest'}}}}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getCollectionsByName': {'post': {'summary': 'Searches for NFT collections based on project name', 'operationId': 'query_nfts_collections_by_name', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getCollectionsByNameRequest'}}}}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/getTotalValue': {'post': {'summary': \"Calculates the total value of a the address's holdings in USD, with breakdown by NFTs and tokens.\", 'operationId': 'query_total_value', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/getTotalValueRequest'}}}}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/walletName': {'post': {'summary': 'Resolves wallet names to the actual solana address, or if it is already a Solana address, it looks up all the wallet names associated with that publickey. This works especially well for .sol, .glow, .backpack, or .poor domains.', 'operationId': 'query_wallet_name', 'requestBody': {'content': {'application/json': {'schema': {'type': 'object', 'properties': {'walletName': {'type': 'string'}}}}}}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}, '/api/handlers/tokenName': {'post': {'summary': 'Searches tokens by name, and returns the mint address, logo, name and symbol for up to 10 relevant, verified tokens.', 'operationId': 'search_token_name', 'requestBody': {'content': {'application/json': {'schema': {'type': 'object', 'properties': {'tokenName': {'type': 'string'}}}}}}, 'responses': {'200': {'description': 'Successful Response'}, '500': {'description': 'Validation Error'}}, 'security': [{'HTTPBearer': []}]}}}, 'components': {'schemas': {'getAccountInfoRequest': {'type': 'object', 'required': ['address'], 'properties': {'address': {'type': 'string', 'description': 'Base58 encoded PublicKey'}}}, 'getSignaturesForAddressRequest': {'title': 'GetSignaturesForAddressRequest', 'type': 'object', 'required': ['address'], 'properties': {'address': {'type': 'string', 'description': 'Base58 encoded PublicKey'}, 'beforeSignature': {'type': 'string'}, 'untilSignature': {'type': 'string'}}}, 'getBalanceRequest': {'title': 'GetBalanceRequest', 'type': 'object', 'required': ['address'], 'properties': {'address': {'title': 'Address', 'type': 'string', 'description': 'Base58 encoded PublicKey'}}}, 'getTransactionRequest': {'type': 'object', 'required': ['signature'], 'properties': {'signature': {'type': 'string'}, 'devMode': {'type': 'boolean'}}}, 'getCollectionsByFloorPriceRequest': {'type': 'object', 'properties': {'maxFloorPrice': {'type': 'number', 'nullable': True}, 'minFloorPrice': {'type': 'number', 'nullable': True}, 'orderBy': {'type': 'string', 'enum': ['ASC', 'DESC'], 'nullable': True}}}, 'getCollectionsByNameRequest': {'type': 'object', 'properties': {'projectName': {'type': 'string'}}}, 'getListedCollectionNFTsRequest': {'type': 'object', 'properties': {'projectId': {'type': 'string'}, 'priceOrder': {'type': 'string', 'nullable': True}, 'pageSize': {'type': 'number', 'nullable': True}}}, 'getTotalValueRequest': {'type': 'object', 'properties': {'address': {'type': 'string', 'description': 'Base58 encoded PublicKey'}}}}, 'securitySchemes': {'HTTPBearer': {'type': 'http', 'scheme': 'bearer'}}}}\u001b[0m\u001b[32;1m\u001b[1;3mNow that I have the OpenAPI spec for the Solana Labs API, I can use it to find the SOL balance of the specified address.\n",
      "Action: requests_post\n",
      "Action Input: {\"url\": \"https://chatgpt.solanalabs.com/api/handlers/getBalance\", \"data\": {\"address\": \"8fbqVvpK3Dj7fdP2c8JJhtD7Zy3n9qtwAeGfbkgPu625\"}}\u001b[0m\u001b[36;1m\u001b[1;3m{\"sol\":0.042545265}\u001b[0m\u001b[32;1m\u001b[1;3mThe address 8fbqVvpK3Dj7fdP2c8JJhtD7Zy3n9qtwAeGfbkgPu625 has a balance of 0.042545265 SOL.\n",
      "Final Answer: 0.042545265 SOL\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "'8fbqVvpK3Dj7fdP2c8JJhtD7Zy3n9qtwAeGfbkgPu625 has 0.042545265 SOL.'\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"How many SOL does 8fbqVvpK3Dj7fdP2c8JJhtD7Zy3n9qtwAeGfbkgPu625 have?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "What is Unified Liquidity Market in Kamino?\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "'Finished running: grade_documents:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Unified Liquidity Market in Kamino is a single liquidity market that allows for higher leverage when lending/borrowing within a certain asset grouping. This market design aims to prevent fragmentation of liquidity and increase yields for lenders by avoiding multi-pool designs. The risk engine in K-Lend enables risk isolation even within this unified liquidity market.'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"What is Unified Liquidity Market in Kamino?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "value[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "Hello\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: grade_documents:'\n",
      "---WEB SEARCH---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis is not a specific question, I should ask for more information or context.\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Hello\"\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'https://en.wikipedia.org/wiki/Hello', 'content': 'P.S. first cost of sender & receiver to manufacture is only $7.00.[12]\\nBy 1889, central telephone exchange operators were known as \\'hello-girls\\' because of the association between the greeting and the telephone.[14][15]\\nA 1918 fiction novel uses the spelling \"Halloa\" in the context of telephone conversations.[16]\\nHullo, hallo, and other spellings\\nHello might be derived from an older spelling variant, hullo, which the American Merriam-Webster dictionary describes as a \"chiefly British variant of hello\",[17] and which was originally used as an exclamation to call attention, an expression of surprise, or a greeting. It also connects the development of hello to the influence of an earlier form, holla, whose origin is in the French holà (roughly, \\'whoa there!\\', from French là \\'there\\').[6] As in addition to hello, halloo,[7] hallo, hollo, hullo and (rarely) hillo also exist as variants or related words, the word can be spelt using any of all five vowels.[8][9][10]\\nTelephone\\nBefore the telephone, greetings often included a name and a time of day, such as \"Good morning, Doctor\", but on the telephone, it isn\\'t immediately known who is speaking or whether they share the same time zone. In the case of Dutch, it was used as early as 1797 in a letter from Willem Bilderdijk to his sister-in-law as a remark of astonishment.[27]\\nWebster\\'s dictionary from 1913 traces the etymology of holloa to the Old English halow and suggests: \"Perhaps from ah + lo; compare Anglo Saxon ealā\".\\n The word was extensively used in literature by the 1860s.[4]\\nEtymology\\nAccording to the Oxford English Dictionary, hello is an alteration of hallo, hollo,[1] which came from Old High German \"halâ, holâ, emphatic imperative of halôn, holôn to fetch, used especially in hailing a ferryman\".[5] It is first attested in writing from 1826.[1]\\nEarly uses\\nHello, with that spelling, was used in publications in the U.S. as early as the 18 October 1826 edition of the Norwich Courier of Norwich, Connecticut.[1]'}, {'url': 'https://music.youtube.com/watch?v=YQHsXMglC9A&list=RDCLAK5uy_mGYde2Wyx9INZd6GbPcMWkxDOu6Utmedw', 'content': 'Add similar content to the end of the queue. Autoplay is on. Player bar'}, {'url': 'https://www.youtube.com/watch?v=YQHsXMglC9A', 'content': 'Listen to \"Easy On Me\" here: http://Adele.lnk.to/EOMPre-order Adele\\'s new album \"30\" before its release on November 19: https://www.adele.comShop the \"Adele...'}, {'url': 'https://dictionary.cambridge.org/us/dictionary/english/hello', 'content': 'Learn the meaning, pronunciation and usage of hello, a common greeting and attention-getter in English. Find out how to say hello in different situations and languages with examples and translations.'}, {'url': 'https://www.merriam-webster.com/dictionary/hello', 'content': 'Learn the origin, usage, and synonyms of the word hello, an expression or gesture of greeting. See examples of hello in sentences and related articles from Merriam-Webster.'}]\u001b[0m\u001b[32;1m\u001b[1;3mI need to review the search results to see if there is any relevant information related to the general greeting \"Hello.\"\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Hello\"\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'https://www.merriam-webster.com/dictionary/hello', 'content': 'Learn the origin, usage, and synonyms of the word hello, an expression or gesture of greeting. See examples of hello in sentences and related articles from Merriam-Webster.'}, {'url': 'https://dictionary.cambridge.org/us/dictionary/english/hello', 'content': 'Learn the meaning, pronunciation and usage of hello, a common greeting and attention-getter in English. Find out how to say hello in different situations and languages with examples and translations.'}, {'url': 'https://music.youtube.com/watch?v=YQHsXMglC9A&list=RDCLAK5uy_mGYde2Wyx9INZd6GbPcMWkxDOu6Utmedw', 'content': 'Add similar content to the end of the queue. Autoplay is on. Player bar'}, {'url': 'https://en.wikipedia.org/wiki/Hello', 'content': 'P.S. first cost of sender & receiver to manufacture is only $7.00.[12]\\nBy 1889, central telephone exchange operators were known as \\'hello-girls\\' because of the association between the greeting and the telephone.[14][15]\\nA 1918 fiction novel uses the spelling \"Halloa\" in the context of telephone conversations.[16]\\nHullo, hallo, and other spellings\\nHello might be derived from an older spelling variant, hullo, which the American Merriam-Webster dictionary describes as a \"chiefly British variant of hello\",[17] and which was originally used as an exclamation to call attention, an expression of surprise, or a greeting. It also connects the development of hello to the influence of an earlier form, holla, whose origin is in the French holà (roughly, \\'whoa there!\\', from French là \\'there\\').[6] As in addition to hello, halloo,[7] hallo, hollo, hullo and (rarely) hillo also exist as variants or related words, the word can be spelt using any of all five vowels.[8][9][10]\\nTelephone\\nBefore the telephone, greetings often included a name and a time of day, such as \"Good morning, Doctor\", but on the telephone, it isn\\'t immediately known who is speaking or whether they share the same time zone. In the case of Dutch, it was used as early as 1797 in a letter from Willem Bilderdijk to his sister-in-law as a remark of astonishment.[27]\\nWebster\\'s dictionary from 1913 traces the etymology of holloa to the Old English halow and suggests: \"Perhaps from ah + lo; compare Anglo Saxon ealā\".\\n The word was extensively used in literature by the 1860s.[4]\\nEtymology\\nAccording to the Oxford English Dictionary, hello is an alteration of hallo, hollo,[1] which came from Old High German \"halâ, holâ, emphatic imperative of halôn, holôn to fetch, used especially in hailing a ferryman\".[5] It is first attested in writing from 1826.[1]\\nEarly uses\\nHello, with that spelling, was used in publications in the U.S. as early as the 18 October 1826 edition of the Norwich Courier of Norwich, Connecticut.[1]'}, {'url': 'https://www.youtube.com/watch?v=YQHsXMglC9A', 'content': 'Listen to \"Easy On Me\" here: http://Adele.lnk.to/EOMPre-order Adele\\'s new album \"30\" before its release on November 19: https://www.adele.comShop the \"Adele...'}]\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered information about the general greeting \"Hello\" from various sources.\n",
      "Final Answer: The general greeting \"Hello\" has a rich history and may have originated from an older spelling variant \"hullo.\" It is commonly used as an expression of surprise, attention, or greeting.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello may have originated from an older spelling variant \"hullo\" and is commonly used as a greeting or expression of surprise.'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"Hello\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "value[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom-openai-api-endpoint-w1RmsYNt-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
